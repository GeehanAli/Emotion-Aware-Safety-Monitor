# Emotion-Aware Safety Monitor for Online Games

A proof-of-concept tool that uses Machine Learning to proactively detect grooming patterns in children's game chats, moving beyond simple keyword filters.

## ğŸš€ The Problem
Current child safety tools rely on keyword filters that miss nuanced, manipulative language used by predators. This project addresses that gap.

## ğŸ’¡ My Solution
I combine:
- **Natural Language Processing** to detect grooming patterns and intent
- **Synthetic Data Generation** to train models without compromising privacy
- **Multi-signal analysis** for more accurate threat detection

## ğŸ“Š Results
Our ML model outperformed traditional keyword filters:
- **Keyword Filter F1-Score:** 0.45
- **Our ML Model F1-Score:** 0.89

## ğŸ›  Quick Start
1. Clone this repo: `git clone https://github.com/yourusername/emotion-aware-safety-monitor`
2. Install dependencies: `pip install -r requirements.txt`
3. Run the analysis: `jupyter notebook notebooks/01_analysis_and_results.ipynb`

## ğŸ“ Project Structure
emotion-aware-safety-monitor/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synthetic_chats.csv          # Your generated dataset
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.py            # Keyword filter implementation
â”‚   â””â”€â”€ ml_model.py                  # Your ML model code
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_analysis_and_results.ipynb  # Main analysis notebook
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ project_approach.md          # Your research and methodology
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitignore                      # Files to exclude from Git
â””â”€â”€ README.md                       # Project overview (MOST IMPORTANT!)


## ğŸ”® Future Work
- Integrate behavioral anomaly detection
- Develop real-time alert system
- Create parent dashboard interface

## ğŸ“„ License
MIT License